{"metadata":{"kernelspec":{"name":"","display_name":""},"language_info":{"name":""}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"97fc14d8-54ff-425f-902d-8058447e93b9","cell_type":"markdown","source":"# Why Python?\n\nYou're already here because you want to learn to use Python for your data analysis and visualizations.\n\n**Perhaps the #1 reason to use Python is because it is so widely used in the scientific community!**\n\nPython can be compared to other high-level, interpreted, object-oriented languages, but is especially great because it is free and open source!\n\nWant to know what these terms mean for you and your work? Read on!\n\n## High level languages\n\nOther high level languages include MatLab, IDL, and NCL. The advantage of high level languages is that they provide built-in functions, data structures, and other utilities that are commonly used, which means it takes less code to get real work done. The disadvantage of high level languages is that they tend to obscure the low level aspects of the machine such as memory use, how many floating point operations are happening, and other information related to performance. C, C++, and Fortran are all examples of lower level languages. The \"higher\" the level of language, the more computing fundamentals are abstracted.\n\n## Interpreted languages\n\nMost of your work is probably already in interpreted languages if you've ever used IDL, NCL, or MatLab (interpreted languages are typically also high level). So you are already familiar with the advantages of this: you don't have to worry about compiling or machine compatibility (it is portable). And you are probably familiar with their deficiencies: sometimes they can be slower than compiled languages and potentially more memory intensive.\n\n## Object Oriented languages\n\nObjects are custom datatypes. For every custom datatype, you usually have a set of operations you might want to conduct. For example, if you have an object that is a list of numbers, you might want to apply a mathematical operation, such as sum, onto this list object in bulk. Not every function can be applied to every datatype; it wouldn't make sense to apply a logarithm to a string of letters or to capitalize a list of numbers. Data and the operations applied to them are grouped together into one object.\n\n## Open source\n\nPython as a language is open source, which means that there is a community of developers behind its codebase. Anyone can join the developer community and contribute to deciding the future of the language. When someone identifies gaps in Python's abilities, they can write up the code to fill these gaps. The open source nature of Python means that Python as a language is very adaptable to the shifting needs of the user community. This harkens back to the idea that the widespread use of Python within the scientific community is a benefit to you! The large Python user base within your field has established high level community Python packages that are available to you in your workflow.\n\nPython is a language designed for rapid prototyping and efficient programming. It is easy to write new code quickly with less typing.\n\n# Installing and Running Python\n\nAn introduction of different ways to run Python code, installing and managing Python with Conda, and running Python with JupyterHub.\n\n*The notes below are adapted from our [textbook](https://earth-env-data-science.github.io/lectures/environment/python_environments.html#) and [Pythia Foundations](https://foundations.projectpythia.org/foundations/getting-started-python/).*\n\n---\n\n## Choosing a Python Platform\n\nThere is no single official platform for the Python language. Here we provide a brief rundown of 3 popular platforms:\n\n1. The terminal,\n2. Jupyter notebooks, and\n3. IDEs (integrated development environments).\n\nHere we hope to provide you with enough information to understand the differences and similarities between each platform, so that you can make the best choice for your work environment and learn along effectively, regardless of your Python platform preference.\n\nIn general, it is always best to test your programs in the same environment in which they will be run. The biggest factors to consider when choosing your platform are:\n\n- What are you already comfortable with?\n- What are the people around you using (peers, coworkers, instructors, etc.)?\n\n### Terminal\n\nFor learners who are familiar with basic [Linux commands](https://cheatography.com/davechild/cheat-sheets/linux-command-line/) and text editors (such as Vim or Nano), running Python in the terminal is the quickest route straight to learning Python syntax without the covering the bells and whistles of a new platform. If you are running Python on a supercomputer, through an HTTP request or SSH tunneling, you might want to consider learning in the terminal.\n\n[How to Run Python in the Terminal](https://foundations.projectpythia.org/foundations/terminal/)\n\n### Jupyter Notebooks\n\nWe highly encourage the use of Jupyter notebooks: a free, open-source, interactive tool running inside a web browser that allows you to run Python code in \"cells.\" This means that your workflow can alternate between code, output, and even Markdown-formatted explanatory sections that create an easy-to-follow analysis or \"computational narrative\" from start to finish. Jupyter notebooks are a great option for presentations or learning tools. For these reasons, Jupyter is very popular among scientists. Most lessons in this book will be taught via Jupyter notebooks.\n\n*More on Running Python on JupyterHub later*\n\n### Other IDEs\n\nIf you code in other languages, you might already have a favorite IDE that will work just as well in Python. [Spyder](https://www.spyder-ide.org) is a Python specific IDE that comes with the [Anaconda download](https://www.anaconda.com/products/distribution). It is perhaps the most familiar IDE if you are coming from languages such as [Matlab](https://www.mathworks.com/products/matlab.html) that have a language specific platform and display a list of variables. [PyCharm](https://www.jetbrains.com/pycharm/) and [Visual Studio Code](https://code.visualstudio.com) are also popular IDEs. Many IDEs offer support for terminal execution, scripts, and Jupyter display. To learn about your specific IDE, visit its official documentation.\n\n## Installing and managing Python with Conda\n\n*This is the general guidance for installing and managing Python with Conda. With the JupyterHub, a set of packages has already been installed and is good to use. More on Pangeo Python Environment later.*\n\nThe easiest way to set up a full-stack scientific Python deployment is to use a\nPython distribution. This is an installation of Python with a set of curated\npackages which are guaranteed to work together.\nFor this class, we recommend the\n**[Anaconda Python Distribution](https://www.anaconda.com/download/)**.\nFollow the link above to obtain a one-click installer for Linux, Mac, or\nWindows.\n(Make sure you select the Python 3 installer, not Python 2.7.)\nIn addition to the packages themselves, Anaconda includes a graphical\nutility to help manage any packages you may want to install which are not\nalready included in the default inclusion list.\n\nIf you set up your python environment using the Anaconda Python Distribution or\nwith miniconda, you should already have the **conda** command available on\nthe command line.\n\nConda is an open-source, cross-platform, language-agnostic package manager and environment management system that allows you to quickly install, run, and update packages within your work environment(s). Conda is a vital component of the Python ecosystem. Understanding it is important, regardless of the platform you chose to run your Python code.\n\nIt is strongly recommended to read official\n[Getting Started with Conda](https://conda.io/docs/user-guide/getting-started.html#)\nguide.\n\nTo create a conda environment, you execute the following command in the terminal:\n\n    $ conda create --name my_environment python=3.9 numpy\n\nThis will create a special environment in ``$MINICONDA_HOME/envs/my_environment``\nwith only Python and numpy to begin with. Here, we've also told conda to install\nPython version 3.9; you can specify exact versions or minima, and conda will\ntake care of figuring out all the compatibilities between versions for you. To use\nthis environment, simply \"activate\" it by executing:\n\n    $ conda activate my_environment\n\nRegardless of your shell, you should now see the string ``(my_environment)``\nprepended to your prompt. Now, if you execute any Python-related tool from the\ncommand line, it will first search in ``$MINICONDA_HOME/envs/my_environment/bin``\nto find them.\n\nYou can deactivate your environment by typing:\n\n    $ conda deactivate\n\nTo see all the environments on your system:\n\n    $ conda info --envs\n\nFor extensive documentation on using environments, please see\n[the conda documentation](https://conda.io/docs/using/envs.html). The most\nimportant feature to review here is the ability to *share and export* your\nenvironment; this is the basis for reproducibility in the scientific Python stack.\nAt any time from the shell, you can execute\n\n    $ conda list --name my_environment\n\nto get a complete summary of all the packages installed in your environment, the\nchannel they were installed from, and their full version info. Using this info,\nyou can create an **environment file** in\n[YAML syntax](http://docs.ansible.com/ansible/latest/YAMLSyntax.html)\nwhich documents the exact\ncontents of your environment. With that file, a new environment with the exact\nconfiguration can be installed by executing\n\n    $ conda env create -f my_environment.yml\n\nBelow we will see an example of an environment file.\n\nIf you want to permanently remove an environment and delete all the data\nassociated with it:\n\n    $ conda env remove --name my_environment \n\n## Installing More Packages\n\nOnce you have a basic Python environment, you can easily add or remove packages\nusing conda.\nConda was created to help manage the complex dependencies and\npre-compiled binary libraries that are necessary in scientific python.\n\nWith it, you can easily install packages from an official, curated set of packages which are\nbuilt and tested for a number of different system configurations on Linux,\nWindows, and macOS\n\n    $ conda install <package-name>\n\nAdditionally, there is a\ncommunity-maintained collection of packages/recipes called\n[conda forge](https://conda-forge.github.io/>)\nwhich is accessible through conda as a special \"channel\"\n\n    $ conda install -c conda-forge <package-name>\n\nA list of packages in conda-forge can be found [here](https://conda-forge.org/packages/).\n\nWhile conda allows you to install almost any science-related package, there may\nbe other general-use python packages you wish to you that are not available in\nvia conda. For these, you can use an alternative installation method.\n\nOutside of the scientific python community,\nthe most common way to install packages is to search for them on the official\n[PyPI](https://pypi.python.org/pypi) index. Once you've found the package you\nwant to install (you may have also just found it on github or elsewhere), you\nuse the **pip** command from a the command line:\n\n    $ pip install <package-name>\n\nThis will fetch the source code, build it, and install it to wherever your\n``$PYTHONPATH`` is set. This works in the vast majority of cases, particularly\nwhen the code you're installing doesn't have any compiled dependencies.\n\nIf you can't find a package on either PyPI or conda-forge, you can always install it\ndirectly from the source code. If the package is on github, ``pip`` already has\nan alias to do this for you:\n\n    $ pip install git+https://github.com/<user>/<package-name>.git\n## Pangeo Python Environment\n\nThe environment on our cloud JupyterHub is a highly curated combination of packages\nmaintained by the [Pangeo Project](http://pangeo.io/).\nThen environment lives at <https://github.com/pangeo-data/pangeo-docker-images/>.\nIn addition to just specifying a combination of packages, this repo automatically\nbuilds [Docker containers](https://docs.docker.com/get-started/).\n\nThe latest Pangeo notebook environment lives at <https://github.com/pangeo-data/pangeo-docker-images/blob/master/pangeo-notebook/environment.yml>.\nBelow are the contents of that file as of 2026-01-20.\n\n\nname: pangeo\nchannels:\n - conda-forge\n - nodefaults\ndependencies:\n - adlfs\n - argopy\n - awscli\n - black\n - boto3\n - bottleneck\n - cartopy\n - cdsapi\n - cfgrib\n - cf_xarray\n - ciso\n - cmocean\n - contextily\n - dask-geopandas\n - dask-ml\n - datashader\n - descartes\n - duckdb-cli\n - earthaccess\n - eofs\n - erddapy\n - esmpy\n - fastjmd95\n - flox\n - fsspec\n - gcm_filters\n - gcsfs>=2025\n - gdal\n - gh\n - gh-scoped-creds\n - geocube\n - geopandas\n - geopy\n - geoviews-core\n - git-lfs\n - google-cloud-sdk\n - gsw\n - h5netcdf\n - h5py\n - holoviews\n - hvplot\n - icechunk\n - intake\n - intake-esm<2025.2.3\n - intake-geopandas\n - intake-stac\n - intake-xarray\n - ipdb\n - ipykernel\n - ipyleaflet\n - ipympl\n - ipytree\n - ipywidgets\n - jupyterlab_code_formatter\n - jupyterlab-git\n - jupyterlab-lsp\n - jupyterlab-myst\n - jupyter-panel-proxy\n - jupyter-resource-usage\n - jupyter-sshd-proxy\n - kerchunk\n - libgdal-arrow-parquet\n - libgdal-netcdf\n - line_profiler\n - lonboard\n - lxml\n - lz4\n - matplotlib-base\n - memory_profiler\n - metpy\n - nb_conda_kernels\n - nbstripout\n - nc-time-axis\n - netcdf4\n - numbagg\n - numcodecs\n - numpy\n - numpy_groupies\n - obstore\n - odc-stac>=0.4.0\n - openssh\n - pandas\n - panel\n - param\n - planetary-computer\n - pop-tools\n - pot\n - pyarrow\n - pycamhd\n - pydap\n - pystac\n - pystac-client\n - python-blosc\n - python-duckdb\n - python-gist\n - python-graphviz\n - python-lsp-ruff\n - python-xxhash\n - rasterio\n - rclone\n - rechunker\n - rio-cogeo\n - rioxarray\n - ruff\n - s3fs\n - satpy\n - scikit-image\n - scikit-learn\n - scipy\n - seaborn\n - sparse\n - snakeviz\n - stackstac\n - tiledb-py\n - timezonefinder\n - virtualizarr\n - watermark\n - xarray\n - xarrayutils\n - xarray_leaflet\n - xarray-spatial\n - xbatcher\n - xclim\n - xesmf\n - xgboost\n - xgcm\n - xhistogram\n - xmip\n - xmitgcm\n - xpublish\n - xrft\n - xskillscore\n - xxhash\n - xvec\n - zarr>=3.0.8\n\n\nWith this environment file, a new environment with the exact\nconfiguration can be installed in another server by executing\n\n    $ conda env create -f environment.yml\n\nActivate this environment\n\n    $ conda activate pangeo\n\nThis environment should be sufficient for all of your work in this class.\n\nIf you are interested, you can [speed things up with Mamba](https://earth-env-data-science.github.io/lectures/environment/python_environments.html#speeding-things-up-with-mamba).\n\n## Running Python on CloudBank JupyterHub \n\n1. When you open your [hub](https://umd.cloudbank.2i2c.cloud/), you can see a “File Browser” on the left sidebar and a Launcher with Notebook, Console, and Other on the right sidebar.\n\n   You can create a directory to store our work. Let's call it `work` (or whatever you want to call it). \n   \n   You can do this in the GUI left sidebar by clicking the new-folder icon. If you prefer to use the command line, you can access a terminal by clicking the icon under the \"Other\" heading in the Launcher.\n\n2. Create a new `mysci.ipynb` file within the `work` folder:\n\n   Do this in the GUI on the left sidebar by clicking the \"+\" icon.\n\n   This will open a new launcher window where you can select a Python kernel under the \"Notebooks\" heading for your project. _You should see \"Python 3\" as in the screenshot above._ Depending on the details of your system, you might see some additional buttons with different kernels.\n\n   Selecting a kernel will open a Jupyter notebook instance and add an untitled file to the left sidebar navigator, which you can then rename to `mysci.ipynb`.\n\n4. Change the first notebook cell to include the classic first command: printing, \"Hello, world!\".\n\n   ```python\n   print(\"Hello, world!\")\n   ```\n   \n5. Run your cell with `Shift`+`Enter` and see that the results are printed below the cell.\n\n6. Save your notebook and exit.\n\n   When you are done with your work, it is time to save and exit.\n\n   To save your file, you can click the \"File\" in the upper left Jupyter toolbar and \"Save\" or use keyboard shortcuts.\n\n   Jupyter allows you to close the browser tab without shutting down the server. When you're done working on your notebook, it's important to shutdown the server to free up memory, especially on a shared system. You can do this by clicking \"Hub Control Panel\" under \"File\" and then \"Stop My Server\".\n\n   Then you can quit Jupyter by clicking \"Log Out\" under \"File\".\n\n7. You can download the course materials with the following link: \n\n~~~\n   https://umd.cloudbank.2i2c.cloud/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2Fmkyoungs%2FAOSC445ClimateDataScience&urlpath=lab%2Ftree%2FAOSC445ClimateDataScience%2F&branch=main\n~~~\n\n\n## More on Jupyter \n\nProject Jupyter is a project and community whose goal is to “develop open-source software, open-standards, and services for interactive computing across dozens of programming languages”. Jupyter consists of four main components: Jupyter Notebooks, Jupyter Kernels, Jupyter Lab, and Jupyter Hub. Jupyter can be executed locally and remotely.\n\n**Jupyter Notebooks**\n\nThe Jupyter Notebook software is an open-source web application that allows you to create and share Jupyter Notebooks (*.ipynb files). Jupyter Notebooks contain executable code, LaTeX equations, visualizations (e.g., plots, pictures), and narrative text. The code does not have to just be Python, other languages such as Julia or R are supported as well.\n\nJupyter Notebooks are celebrated for their interactive output that allows movement between code, code output, explanations, and more code - similar to how scientists think and solve problems. Jupyter Notebooks can be thought of as a living, runnable publication and make for a great presentation platform.\n\n**Jupyter Kernels**\n\nSoftware engines and their environments (e.g., conda environments) that execute the code contained in Jupyter Notebooks.\n\n**Jupyter Lab**\n\nA popular web application on which users can create and write their Jupyter Notebooks, as well as explore data, install software, etc.\n\n**Jupyter Hub**\n\nA web-based platform that authenticates users and launches Jupyter Lab applications for users on remote systems.\n","metadata":{}},{"id":"f08e77c6-41f5-4462-b23c-a8ba3dc0ba92","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
